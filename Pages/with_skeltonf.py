import streamlit as st
import cv2
import numpy as np
import pandas as pd
import joblib
import mediapipe as mp
from collections import deque
from streamlit_TTS import text_to_speech
from gtts.lang import tts_langs
import uuid
import time

#---------------------------Set page configuration------------------------------
st.set_page_config(
    page_title="SSLT - Real-Time Saudi Sign Language Translator",
    page_icon="ğŸ™ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
)

#---------------------------Custom CSS for styling------------------------------
st.markdown("""
<style>
.Main-Title {
    font-size: 58px;
    font-weight: bold;
    text-align: center;
    background: -webkit-linear-gradient(45deg, #004474, #ff5733, #28a745);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
}
.Prediction-Text {
    font-size: 60px;
    font-weight: bold;
    text-align: center;
    background: -webkit-linear-gradient(45deg, #004474, #ff5733, #28a745);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
}
.Confidence-Text {
    font-size: 40px;
    text-align: center;
    color: gray;
}
.image-container {
    display: flex;
    justify-content: center;
    align-items: center;
}
.video-box {
    width: 480px;
    height: auto;
    border-radius: 10px;
    box-shadow: 0px 0px 10px rgba(0,0,0,0.3);
}
</style>
""", unsafe_allow_html=True)

#---------------------------App Title & Intro-------------------------------
st.markdown("<div class='Main-Title'>ğŸ™ï¸ Ù…ØªØ±Ø¬Ù… Ù„ØºØ© Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© (SSLT)</div>", unsafe_allow_html=True)
st.markdown("---")

st.markdown('<p style="font-size: 24px; text-align: center;">Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…ØªØ±Ø¬Ù… Ø§Ù„Ø¥Ø´Ø§Ø±ÙŠ Ø§Ù„ÙÙˆØ±ÙŠ!</p>', unsafe_allow_html=True)
st.markdown('<p style="font-size: 18px; text-align: center;">Ù‚Ù… Ø¨Ø¹Ø±Ø¶ Ø¥ÙŠÙ…Ø§Ø¡Ø© Ø£Ù…Ø§Ù… Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ØŒ ÙˆØ³ÙˆÙ ÙŠÙÙ†Ø·Ù‚ Ø§Ù„ÙƒÙ„Ù…Ø© ÙÙˆØ±Ø§Ù‹ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.</p>', unsafe_allow_html=True)

#---------------------------Sidebar-------------------------------------
with st.sidebar:
    st.markdown("<h1 class='SideBar' style='color:orange;'>SSLT</h1>", unsafe_allow_html=True)
    st.markdown("---")
    
    with st.expander("ğŸ› ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª", expanded=True):
        predict_every_n_frames = st.slider("ØªÙƒØ±Ø§Ø± Ø§Ù„ØªÙ†Ø¨Ø¤ (ÙƒÙ„ N Ø¥Ø·Ø§Ø±)", 1, 120, 10)
        langs = list(tts_langs().keys())
        selected_lang = st.selectbox("Ø§Ø®ØªØ± Ù„ØºØ© Ø§Ù„Ù†Ø·Ù‚", options=langs, index=langs.index('ar'))
        st.markdown("---")

    with st.expander("ğŸª„ ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…", expanded=True):
        st.markdown("""
        <ul style="font-size: 18px;">
            <li>Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± <strong>'ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§'</strong></li>
            <li>Ø§Ø³ØªØ®Ø¯Ù… ÙŠØ¯ÙŠÙƒ Ù„Ø¥Ø¸Ù‡Ø§Ø± Ø§Ù„Ø¥ÙŠÙ…Ø§Ø¡Ø©</li>
            <li>Ø³ÙŠØªÙ… Ø¹Ø±Ø¶ ÙˆÙ†Ø·Ù‚ Ø§Ù„ÙƒÙ„Ù…Ø© ÙÙˆØ±ÙŠØ§Ù‹</li>
            <li>Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± <strong>'Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§'</strong> Ø¹Ù†Ø¯ Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡</li>
        </ul>
        """, unsafe_allow_html=True)

#---------------------------Load Model-------------------------------
@st.cache_resource
def load_model():
    return joblib.load(r"/workspaces/SSLT/Pages/ssl_hand_gesture_model.pkl")  # Use relative path for deployment

model = load_model()

labels = ["Ø³Ù†Ø©", "Ø£Ø³Ø¨ÙˆØ¹", "Ø´Ù‡Ø±", "Ø§Ù„Ø£Ø±Ø¨Ø¹Ø§Ø¡", "Ø§Ù„Ø¬Ù…Ø¹Ø©", "Ø§Ù„Ø«Ù„Ø§Ø«Ø§Ø¡", "Ø§Ù„Ø£Ø«Ù†ÙŠÙ†", "Ø§Ù„Ø£Ø­Ø¯", "ÙŠÙˆÙ…", "Ø§Ù„Ø®Ù…ÙŠØ³", "Ø§Ù„Ø³Ø¨Øª", "Ù„ØºØ© Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©"]

#---------------------------Session State-------------------------------
if 'camera_running' not in st.session_state:
    st.session_state.camera_running = False
    st.session_state.prediction = None
    st.session_state.confidence = 0.0
    st.session_state.last_prediction = None

#---------------------------MediaPipe Setup-----------------------------
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils
mp_styles = mp.solutions.drawing_styles

hands = mp_hands.Hands(
    static_image_mode=False,
    max_num_hands=2,
    min_detection_confidence=0.7,
    min_tracking_confidence=0.7
)

#---------------------------Camera Logic-------------------------------
video_placeholder = st.empty()
prediction_placeholder = st.empty()

if st.session_state.camera_running:
    cap = cv2.VideoCapture(0)
    frame_count = 0

    while st.session_state.camera_running:
        ret, frame = cap.read()
        if not ret:
            st.error("ÙØ´Ù„ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§.")
            break

        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = hands.process(image_rgb)

        landmarks = []

        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                mp_drawing.draw_landmarks(
                    frame,
                    hand_landmarks,
                    mp_hands.HAND_CONNECTIONS,
                    mp_styles.get_default_hand_landmarks_style(),
                    mp_styles.get_default_hand_connections_style()
                )
                for lm in hand_landmarks.landmark:
                    landmarks.extend([lm.x, lm.y, lm.z])

        prediction = "..."
        confidence = 0.0

        if len(landmarks) == 126:
            df = pd.DataFrame([landmarks])
            prediction = model.predict(df)[0]
            confidence = 1.0

            if prediction != st.session_state.last_prediction:
                st.session_state.last_prediction = prediction
                text_to_speech(text=prediction, language=selected_lang, key=f"tts_{uuid.uuid4()}")

            st.session_state.prediction = prediction
            st.session_state.confidence = confidence

        # Show webcam feed in a small container
        with video_placeholder.container():
            col1, col2 = st.columns([2, 1])  # Video on left, prediction on right
            with col1:
                st.markdown('<div class="video-box">', unsafe_allow_html=True)
                st.image(frame, channels="BGR", width=320)
                st.markdown('</div>', unsafe_allow_html=True)
            with col2:
                if st.session_state.prediction:
                    st.markdown(f"""
                    <p class="Prediction-Text">
                    Ø§Ù„ØªÙ†Ø¨Ø¤: <strong>{st.session_state.prediction}</strong><br>
                    <span class="Confidence-Text">Ø§Ù„Ø«Ù‚Ø©: {int(st.session_state.confidence * 100)}%</span>
                    </p>
                    """, unsafe_allow_html=True)

        frame_count += 1
        time.sleep(0.01)

    cap.release()
else:
    prediction_placeholder.markdown('<p class="Prediction-Text" style="font-size: 40px; text-align:center;">ğŸ”´ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ù…Ø¹Ø·Ù„Ø©. Ø§Ø¶ØºØ· ØªØ´ØºÙŠÙ„ Ù„Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¹Ø±Ù.</p>', unsafe_allow_html=True)

#---------------------------Camera Controls-------------------------------
col1, col2 = st.columns(2)
with col1:
    if st.button("ğŸ¥ğŸŸ¢ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§", key="start_camera", use_container_width=True):
        st.session_state.camera_running = True
        st.session_state.prediction = None
        st.session_state.confidence = 0.0
        st.session_state.last_prediction = None

with col2:
    if st.button("ğŸ¥ğŸ›‘ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§", key="stop_camera", use_container_width=True):
        st.session_state.camera_running = False

#---------------------------Footer------------------------------------
st.markdown("---")
st.markdown(
    """
    <footer style="text-align: center; margin-top: 50px;">
        <p>Â© 2025 Saudi Sign Language Translator | ØªÙ… Ø¨Ù†Ø§Ø¤Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Streamlit + MediaPipe + Scikit-learn</p>
    </footer>
    """,
    unsafe_allow_html=True
)
